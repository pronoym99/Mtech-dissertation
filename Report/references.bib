@Misc{bochkovskiy2020yolov4,
  author        = {Alexey Bochkovskiy and Chien-Yao Wang and Hong-Yuan Mark Liao},
  title         = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2004.10934},
  primaryclass  = {cs.CV},
}

@InProceedings{Wang_2021_CVPR,
  author    = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {{Scaled-YOLOv4}: Scaling Cross Stage Partial Network},
  year      = {2021},
  month     = {6},
  pages     = {13029-13038},
}

@Article{yolov3,
  author  = {Redmon, Joseph and Farhadi, Ali},
  journal = {arXiv},
  title   = {YOLOv3: An Incremental Improvement},
  year    = {2018},
}

@Electronic{Rajput2021,
  author   = {Vishal Rajput},
  language = {English},
  month    = {12},
  title    = {YOLO v4 explained in full detail},
  url      = {https://medium.com/aiguys/yolo-v4-explained-in-full-detail-5200b77aa825},
  year     = {2021},
}

@Electronic{Koech2020,
  author   = {Kiprono Elijah Koech},
  language = {English},
  month    = {8},
  title    = {Object Detection Metrics With Worked Example},
  url      = {https://towardsdatascience.com/on-object-detection-metrics-with-worked-example-216f173ed31e},
  year     = {2020},
}

@article{adapt,
title = {Adaptive key frame extraction for video summarization using an aggregation mechanism},
journal = {Journal of Visual Communication and Image Representation},
volume = {23},
number = {7},
pages = {1031-1040},
year = {2012},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2012.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S1047320312001095},
author = {Naveed Ejaz and Tayyab Bin Tariq and Sung Wook Baik},
keywords = {Key frame extraction, Video summarization, Video abstraction, Static video summary, Storyboard, Video analysis, Evaluation of video summary, Feature aggregation},
abstract = {Video summarization is a method to reduce redundancy and generate succinct representation of the video data. One of the mechanisms to generate video summaries is to extract key frames which represent the most important content of the video. In this paper, a new technique for key frame extraction is presented. The scheme uses an aggregation mechanism to combine the visual features extracted from the correlation of RGB color channels, color histogram, and moments of inertia to extract key frames from the video. An adaptive formula is then used to combine the results of the current iteration with those from the previous. The use of the adaptive formula generates a smooth output function and also reduces redundancy. The results are compared to some of the other techniques based on objective criteria. The experimental results show that the proposed technique generates summaries that are closer to the summaries created by humans.}
}

@Electronic{Brownlee2020,
  author       = {Jason Brownlee},
  language     = {English},
  month        = aug,
  organization = {Machine Learning Mastery},
  title        = {Deep Learning Models for Multi-Output Regression},
  url          = {https://machinelearningmastery.com/deep-learning-models-for-multi-output-regression/},
  year         = {2020},
}

@Electronic{Jaided2020,
  author       = {Jaided AI},
  language     = {English},
  month        = mar,
  organization = {Jaided AI},
  title        = {EasyOCR},
  url          = {https://github.com/JaidedAI/EasyOCR},
  year         = {2020},
}

@Electronic{Google2015,
  author       = {Google},
  language     = {English},
  month        = jul,
  organization = {Google},
  title        = {Tesseract OCR},
  url          = {https://tesseract-ocr.github.io/},
  year         = {2015},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectoryLatex-Microsoft-HOME-PC:G:\\PRONOY\\Mtech-dissertation;}
