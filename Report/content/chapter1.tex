\chapter{Introduction}

\thispagestyle{empty} % no page number for introduction

\setcounter{page}{2} % remember counting now starts from 2
\pagenumbering{arabic} % style changes back to arabic

\section{Dissertation name and title}
My dissertation is titled \textbf{Analysis of stock market recommendations using computer vision}.

\section{Problem statement}

There is a large no. of daily broadcasts which take place throughout primetime (morning and evening) as well as outside of it. This project aims to digitize as well as summarise the recommendations cumulatively and present them to the end-user at the same time this project and its associated machine learning system are input to more sophisticated models for anomaly detection (in the context of violations in the securities market) at a later stage.

\section{Proposed solution}
The proposed solution is a deep learning model aimed at solving two fundamental machine learning problems at hand:
\begin{enumerate}

  \item	Object detection – Detect and classify important regions of interest in the frames of various NEWS broadcasts (or NEWS shows) i.e. regions having (but not restricted to) the name of the analyst/presenter, the recommendation being given, the company, commodity or the market segment being discussed and its corresponding listing symbol (if any), the various metrics of the recommendation such as stop loss, target price etc.

  \item  Optical Character Recognition (OCR) – Bilingual (English and Hindi) text obtained from the above regions of interest is passed onto sophisticated OCR models which have a text detection model and an actual language model(s) (corresponding to the concerned languages) working under the hood to obtain or extract the required information.

\end{enumerate}

The final output consists of a CSV (or) an excel file as required which summarises the above-obtained information.

\section{Scope and report contents}

Chapter \ref{chapter2} goes into a detailed discussion of the literature which has been studied while preparing this report. It includes several details such as (but not restricted to) how \textbf{YoLo} models or in general object detection models are evaluated and which performance metrics and common datasets are referred to for their speed and accuracy. It has additional details regarding how advanced deep learning models like \textbf{YoLov4} can be optimised for special use cases wherein necessary.
The complete work presented in this dissertation report is broadly divided into two parts which may be completed sequentially or parallelly and are described as follows. Additionally, the chapters to which they pertain to are also mentioned.

\begin{enumerate}
  \item Machine learning and computer vision: There are a total of 8 NEWS shows which are currently being targeted under this project. Machine learning used within this project is further divided into two parts: the one dealing with the recognition of various numerical parameters from the video frames of a broadcast (wherein active work is going on to increase efficiency as well as the accuracy of models) are random forest classifiers which have been trained on a large number of video frames which were earlier trained on \textbf{YoLov3} output (but needed additional training due to lesser accuracy) and templates followed by a much more robust and reliable framework i.e. YoLov4 which has been trained only for one NEWS show (i.e. \textit{PehlaSauda} from CNBC Awaaz). \par

  The second part of ML goes into OCR models wherein \textbf{no active work is being pursued} rather readymade models and OCR engines that are doing the job within tolerable error limits are being used. Both Tesseract – OCR and EasyOCR provided models have been used for this purpose and their performance metrics analysed. It should be noted that \textbf{no part of the report} goes into the details of the inner workings of the OCR models which are deep learning models in themselves. \par

  As opposed to standard ML projects wherein a considerable amount of time is used for training a particular model; this project uses more time and space to carry out a variety of image processing operations on the captured video frames. This includes histogram equalization, simple grey level transformations as well as complex erosion and dilation processes. After carrying out sufficient thresholding operations, these are fed into the ML models described above.

  The details for the above i.e. the process of collecting the data, preparing the data for training and testing and using appropriate deep learning models for the same are discussed in \ref{chapter3} in detail.

  \item Deployment into production: Rarely do data science projects in academia ever reach production and into a streamlined architecture. There are several reasons which prevent it from happening so. Such details, as well as reasons, have been given in brief in chapter \ref{chapter4}’s opening sections. \par
   Fortunately, for this project, the deployment of the data models falls within its current scope. All the ML models which would be trained and tested would be loaded onto the proprietary \textbf{Ezmeral MLOPs} platform by \textbf{HPE}. The servers for the same reside alongside the required hardware resources on SEBI’s internal servers. Doing this (without going into the details) would make the entire process streamlined i.e. the process of uploading videos, and training models on new data as soon as it is available and at the same time would decrease the manual work involved while doing so. As soon as the deployment has been completed, whether for all the NEWS shows or even a few of them, the internal server would be able to serve requests from within the organization domain (\textit{POST} methods with \textit{JSON} body) and at the same time would be able to abstract all the complex code and scripts running in the background. \par

   Apart from the MLOPs deployment, it is more desirable for SEBI to have a continuously running workflow that shall consist of processing a bulk or a batch of videos at once. A workflow about this has been deployed on a standalone virtual machine as a part of this project. Which projects require an MLOPs workflow and which don’t, as a result, have also been discussed in chapter \ref{chapter4}.
\end{enumerate}


Chapter \ref{chapter5} would then go on to discuss the various results which have been obtained at the end in terms of speed and accuracy of the YoLo models involved which metrics are suitable for evaluating projects spanning multiple ML models. Chapter \ref{chapter6} of the report would then finally present important conclusions drawn from the entire project.
